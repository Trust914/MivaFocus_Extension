name: Auto Update Course Database

on:
  schedule:
    - cron: '0 2 * * 0'
  workflow_dispatch:
  push:
    branches:
      - master
    paths:
      - 'scrape_courses.py'
      - 'auto_update.py'
      - 'settings.py'

jobs:
  update-courses:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 lxml python-dotenv
      
      - name: Run course scraper
        id: scrape
        env:
          # Base Configuration
          BASE_URL: ${{ secrets.BASE_URL  }}
          FACULTIES_URL: ${{ secrets.FACULTIES_URL  }}
          
          # Scraping Configuration
          TIMEOUT: ${{ secrets.TIMEOUT }}
          MAX_WORKERS: ${{ secrets.MAX_WORKERS}}
          PARSER: ${{ secrets.PARSER }}
          MAX_RETRIES: ${{ secrets.MAX_RETRIES}}
          RETRY_DELAY: ${{ secrets.RETRY_DELAY}}
          USER_AGENT: ${{ secrets.USER_AGENT }}
          
          # Output Configuration
          OUTPUT_DIR: ${{ secrets.OUTPUT_DIR }}
          FULL_DATA_FILENAME: ${{ secrets.FULL_DATA_FILENAME }}
          EXTENSION_FILENAME: ${{ secrets.EXTENSION_FILENAME }}
          CHANGELOG_FILENAME: ${{ secrets.CHANGELOG_FILENAME }}
          
          # Logging Configuration
          LOG_FILE: ${{ secrets.LOG_FILE  }}
          LOG_LEVEL: ${{ secrets.LOG_LEVEL }}
          LOG_FORMAT: ${{ secrets.LOG_FORMAT }}
          LOG_ENCODING: ${{ secrets.LOG_ENCODING}}
          
          # Metadata Configuration
          METADATA_VERSION: ${{ secrets.METADATA_VERSION }}
          METADATA_ACADEMIC_YEAR: ${{ secrets.METADATA_ACADEMIC_YEAR }}
          METADATA_SCRAPER: ${{ secrets.METADATA_SCRAPER }}
          
          # Change Detection Configuration
          CREATE_INITIAL_CHANGELOG: ${{ secrets.CREATE_INITIAL_CHANGELOG }}
          ALWAYS_SAVE_FULL_DATA: ${{ secrets.ALWAYS_SAVE_FULL_DATA }}
        run: |
          python auto_update.py
          echo "Scraper finished with exit code: $?"
          ls -la *.json *.txt *.md 2>/dev/null || echo "No output files found"
      
      - name: Commit and push changes
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          # Add all generated files
          git add -f courses_database.json miva_courses_full.json .courses_hash.txt CHANGELOG.md 2>/dev/null || true
          
          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No changes to commit"
            echo "has_changes=false" >> $GITHUB_OUTPUT
          else
            echo "Changes detected, committing..."
            git commit -m "chore: auto-update course database [skip ci]"
            git push
            echo "has_changes=true" >> $GITHUB_OUTPUT
          fi
        id: commit
      
      - name: Upload artifacts (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: course-data-${{ github.run_number }}
          path: |
            courses_database.json
            miva_courses_full.json
            CHANGELOG.md
            scraper.log
            .courses_hash.txt
          retention-days: 30